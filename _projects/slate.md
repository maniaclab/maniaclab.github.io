---
layout: post
title: SLATE
categories: [projects]
author: Jeremy Van
icon: /assets/projects/slate-logo.png
image: /assets/projects/slate-diagram.png
excerpt: A SLATE edge platform within a campus Science DMZ hosts trusted services operated by a central team which might be operating a network of such services across several campuses.
---
## What is SLATE?

A SLATE edge platform within a campus Science DMZ hosts trusted services operated
by a central team which might be operating a network of such services across
several campuses. Science “app” developers interact with the SLATE platform
service factory to define and launch elements of a science gateway, data cache,
or local workflow service.

“Services Layer At The Edge (SLATE) and the Mobility of Capability”, a project
funded by the National Science Foundation in 2017, aims to address these challenges.
A team from the Enrico Fermi and Computation Institutes at University of Chicago,
the Center for Network and Storage-Enabled Collaborative Computational Science at
the University of Michigan, and the Center for High Performance Computing at the
University of Utah, working with the national advanced cyberinfrastructure
community will foster technology that simplifies connecting university and
laboratory data center capabilities to the national cyberinfrastructure ecosystem.

## Why SLATE?
Deploying science services across national and international distributed
infrastructures is hard! Rolling out hardware, Operating Systems, science
applications, and science tools at every geographically discrete site requires a
significant IT presence at each site. The IT personnel have to deal with the
hardware, the IT software, AND the science software in order to make a science
service function. This fact requires a lot of knowledge and time on the order
of days, weeks, and months. SLATE aims to make the job easier for the local IT
support person and to minimize the time to deployment for the science services.


Once installed, SLATE connects local research groups with their far-flung
collaborators, allowing central research teams to automate the exchange of data,
software and computing tasks among institutions without burdening local system
administrators with installation and operation of highly customized scientific
computing services. By stitching together these resources, SLATE will also expand
the reach of domain-specific “science gateways” and multi-site research platforms.

SLATE will implement “cyberinfrastructure as code”, augmenting high bandwidth
science networks with a programmable “underlayment” edge platform. This platform
hosts advanced services needed for higher-level capabilities such as data and
software delivery, workflow services and science gateway components.

SLATE will use best-of-breed data center virtualization components, and where
available, software defined networking, to enable automation of lifecycle
management tasks by domain experts. As such, it simplifies the creation of
scalable platforms that connect research teams, institutions and resources,
accelerating science while reducing operational costs and development time.
Since SLATE needs only commodity components, it can be used for distributed
systems across all data center types and scales, thus enabling creation of
ubiquitous, science-driven cyberinfrastructure.
